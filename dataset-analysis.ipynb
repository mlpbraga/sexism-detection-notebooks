{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from modules.dataframe import Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>votes</th>\n",
       "      <th>avg</th>\n",
       "      <th>std</th>\n",
       "      <th>label</th>\n",
       "      <th>char-qty</th>\n",
       "      <th>word-qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489</td>\n",
       "      <td>MUITO MAIS LEGAL  RRSRSRRSRSRS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>Canhão de guerra.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2574</td>\n",
       "      <td>femi o que?</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>951</td>\n",
       "      <td>Concordo plenamente Jaqueline!! Outro dia ouvi...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2520</td>\n",
       "      <td>Feminista é uma mulher encalhada que precisa d...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>55</td>\n",
       "      <td>Brigue esquisitinha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>3858</td>\n",
       "      <td>Pois é, todo o bozopata é assim! Depois que pe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>3984</td>\n",
       "      <td>Será que ninguém tem coragem de enfrentar algu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>790</td>\n",
       "      <td>Perfeito!</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>2850</td>\n",
       "      <td>Impressão sua, a diferença é que agora você vê...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3571 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id                                            content  likes  \\\n",
       "0           1489                     MUITO MAIS LEGAL  RRSRSRRSRSRS    2.0   \n",
       "1            273                                 Canhão de guerra.     2.0   \n",
       "2           2574                                        femi o que?   10.0   \n",
       "3            951  Concordo plenamente Jaqueline!! Outro dia ouvi...   20.0   \n",
       "4           2520  Feminista é uma mulher encalhada que precisa d...   11.0   \n",
       "...          ...                                                ...    ...   \n",
       "3566          55                                Brigue esquisitinha    0.0   \n",
       "3567        3858  Pois é, todo o bozopata é assim! Depois que pe...    3.0   \n",
       "3568        3984  Será que ninguém tem coragem de enfrentar algu...    0.0   \n",
       "3569         790                                          Perfeito!    2.0   \n",
       "3570        2850  Impressão sua, a diferença é que agora você vê...    4.0   \n",
       "\n",
       "      dislikes  votes       avg      std  label  char-qty  word-qty  \n",
       "0          0.0      2  0.000000  0.00000      0        30         5  \n",
       "1          4.0      2  1.000000  0.00000      1        18         4  \n",
       "2         11.0      2  1.000000  0.00000      1        11         3  \n",
       "3          0.0      3  0.666667  0.57735      1       161        27  \n",
       "4         11.0      3  1.000000  0.00000      1        66        11  \n",
       "...        ...    ...       ...      ...    ...       ...       ...  \n",
       "3566       1.0      3  0.666667  0.57735      1        19         2  \n",
       "3567       0.0      3  0.333333  0.57735      0       192        35  \n",
       "3568       0.0      1  0.000000      NaN      0       368        60  \n",
       "3569       2.0      3  0.333333  0.57735      0         9         1  \n",
       "3570       0.0      3  0.333333  0.57735      0       270        44  \n",
       "\n",
       "[3571 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_comments = pd.read_csv('data/labeled-comments.csv')\n",
    "labeled_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Dataset fields description</b>\n",
    "    <hline/>\n",
    "    <p><b>comment_id</b>: unique identifier to each comment from database</p>\n",
    "    <p><b>content</b>: comment text content</p>\n",
    "    <p><b>likes</b>: comment likes quantity</p>\n",
    "    <p><b>dislikes</b>: comment dislikes quantity</p>\n",
    "    <p><b>votes</b>: number of users that labeled the comment</p>\n",
    "    <p><b>avg</b>: average of each vote value to the comment</p>\n",
    "    <p><b>std</b>: standard deviation of each vote value to the comment</p>\n",
    "    <p><b>label</b>: final label assigned to the comment, label 1 represents sexist comments and label 0 represets not sexist comments</p>\n",
    "    <p><b>char-qty</b>: number of characters in the comment </p>\n",
    "    <p><b>word-qty</b>: number of words in the comment</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>votes</th>\n",
       "      <th>avg</th>\n",
       "      <th>std</th>\n",
       "      <th>label</th>\n",
       "      <th>char-qty</th>\n",
       "      <th>word-qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3323.000000</td>\n",
       "      <td>3323.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>2886.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1923.082610</td>\n",
       "      <td>15.611496</td>\n",
       "      <td>9.856455</td>\n",
       "      <td>2.534304</td>\n",
       "      <td>0.523321</td>\n",
       "      <td>0.230954</td>\n",
       "      <td>0.523663</td>\n",
       "      <td>140.439373</td>\n",
       "      <td>24.494539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1135.048496</td>\n",
       "      <td>40.102726</td>\n",
       "      <td>41.783877</td>\n",
       "      <td>1.032327</td>\n",
       "      <td>0.420923</td>\n",
       "      <td>0.277073</td>\n",
       "      <td>0.499510</td>\n",
       "      <td>178.984760</td>\n",
       "      <td>27.111817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>988.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1886.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2783.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4283.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7050.000000</td>\n",
       "      <td>819.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment_id        likes     dislikes        votes          avg  \\\n",
       "count  3571.000000  3323.000000  3323.000000  3571.000000  3571.000000   \n",
       "mean   1923.082610    15.611496     9.856455     2.534304     0.523321   \n",
       "std    1135.048496    40.102726    41.783877     1.032327     0.420923   \n",
       "min       4.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "25%     988.500000     2.000000     0.000000     2.000000     0.000000   \n",
       "50%    1886.000000     5.000000     1.000000     3.000000     0.666667   \n",
       "75%    2783.500000    14.000000     6.000000     3.000000     1.000000   \n",
       "max    4283.000000   729.000000  1196.000000     7.000000     1.000000   \n",
       "\n",
       "               std        label     char-qty     word-qty  \n",
       "count  2886.000000  3571.000000  3571.000000  3571.000000  \n",
       "mean      0.230954     0.523663   140.439373    24.494539  \n",
       "std       0.277073     0.499510   178.984760    27.111817  \n",
       "min       0.000000     0.000000     2.000000     1.000000  \n",
       "25%       0.000000     0.000000    47.000000     9.000000  \n",
       "50%       0.000000     1.000000    94.000000    17.000000  \n",
       "75%       0.577350     1.000000   179.000000    32.000000  \n",
       "max       0.577350     1.000000  7050.000000   819.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_comments.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "A visual data analysis is avaliable at https://datastudio.google.com/s/sgO8X7JORMU\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating dataset features and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> No comments without label\n",
      "> Loading local dataframe\n"
     ]
    }
   ],
   "source": [
    "from classifiers.features import Features\n",
    "\n",
    "# The Comments class is responsable for structuring data about\n",
    "# the comments, it's source code can be analized at:\n",
    "# https://github.com/mlpbraga/sexism-detection-notebooks/blob/main/modules/dataframe.py\n",
    "comments = Comments()\n",
    "\n",
    "# The Features class is responsable for turning features structured\n",
    "# above into an python objetect, it's source code can be analized at:\n",
    "# https://github.com/mlpbraga/sexism-detection-notebooks/blob/main/classifiers/features.py\n",
    "features = Features(comments.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>homens</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>ela</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>mulher</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>de</td>\n",
       "      <td>0.040850</td>\n",
       "      <td>0.038762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>elas</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>feia</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>uma</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>as</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>na</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>diz</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>assédio</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>feminismo</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>feministas</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>As</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "3844    mulheres     0.009752         0.006359               0  0.003393\n",
       "3834      homens     0.006732         0.003903               0  0.002829\n",
       "3836         ela     0.007480         0.005013               0  0.002466\n",
       "3845      mulher     0.010040         0.007907               0  0.002133\n",
       "3852          de     0.040850         0.038762               0  0.002089\n",
       "3804        elas     0.002445         0.000471               0  0.001974\n",
       "3795        feia     0.002129         0.000202               0  0.001927\n",
       "3847         uma     0.011996         0.010195               0  0.001801\n",
       "3841          as     0.008803         0.007066               0  0.001737\n",
       "3837          na     0.007882         0.006191               0  0.001691\n",
       "3782         diz     0.001697         0.000303               0  0.001394\n",
       "3798     assédio     0.002244         0.000875               0  0.001369\n",
       "3802   feminismo     0.002388         0.001043               0  0.001345\n",
       "3787  feministas     0.001812         0.000505               0  0.001308\n",
       "3754          As     0.001438         0.000404               0  0.001035"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sexist_words.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>ser</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>sua</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>não</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>comentários</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>em</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>pessoas</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>sobre</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>lei</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>você</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>presidente</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>mundo</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>ainda</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>está</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>seus</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "3830          ser     0.005523         0.007907               0 -0.002384\n",
       "3727       Brasil     0.001093         0.002692               0 -0.001599\n",
       "3758          sua     0.001467         0.003028               0 -0.001561\n",
       "3851          não     0.022007         0.023419               0 -0.001411\n",
       "3372  comentários     0.000345         0.001581               0 -0.001236\n",
       "3839           em     0.008487         0.009690               0 -0.001204\n",
       "3732      pessoas     0.001122         0.002322               0 -0.001200\n",
       "3550        sobre     0.000518         0.001716               0 -0.001198\n",
       "3616          lei     0.000690         0.001817               0 -0.001127\n",
       "3779         você     0.001640         0.002759               0 -0.001119\n",
       "3244   presidente     0.000259         0.001346               0 -0.001087\n",
       "3759        mundo     0.001496         0.002456               0 -0.000960\n",
       "3750        ainda     0.001410         0.002322               0 -0.000912\n",
       "3803         está     0.002417         0.003297               0 -0.000881\n",
       "3548         seus     0.000518         0.001346               0 -0.000828"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.not_sexist_words.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>as mulheres</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>diz que</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>que homens</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>que as</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>que vai</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>os homens</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>mesmo que</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>uma mulher</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>mulheres não</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>mulheres que</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>um homem</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>as feministas</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>são minoria</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>não tem</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>por causa</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "4213    as mulheres     0.009315         0.005705               0  0.003610\n",
       "4203        diz que     0.003670         0.000423               0  0.003247\n",
       "4201     que homens     0.003481         0.000423               0  0.003059\n",
       "4208         que as     0.004610         0.001902               0  0.002709\n",
       "4199        que vai     0.003293         0.000845               0  0.002448\n",
       "4210      os homens     0.005081         0.002853               0  0.002228\n",
       "4198      mesmo que     0.003199         0.001162               0  0.002037\n",
       "4211     uma mulher     0.006022         0.004332               0  0.001690\n",
       "4193   mulheres não     0.002635         0.000951               0  0.001684\n",
       "4195   mulheres que     0.003011         0.001585               0  0.001426\n",
       "4192       um homem     0.002540         0.001162               0  0.001378\n",
       "4172  as feministas     0.001882         0.000528               0  0.001354\n",
       "4157    são minoria     0.001505         0.000211               0  0.001294\n",
       "4207        não tem     0.004610         0.003381               0  0.001230\n",
       "4176      por causa     0.001882         0.000740               0  0.001142"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sexist_bigrams.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>que não</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>ser humano</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>ou não</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>no Brasil</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>todos os</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>as pessoas</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>tem que</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>pessoas que</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>maioria dos</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>que você</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>não sabe</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>todo mundo</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>de sua</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>sabe que</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>que ser</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "4212      que não     0.007810         0.010037               0 -0.002227\n",
       "3947   ser humano     0.000565         0.002430               0 -0.001865\n",
       "3926       ou não     0.000565         0.002007               0 -0.001443\n",
       "4175    no Brasil     0.001882         0.003170               0 -0.001288\n",
       "4167     todos os     0.001694         0.002958               0 -0.001265\n",
       "4112   as pessoas     0.001035         0.002219               0 -0.001184\n",
       "4202      tem que     0.003481         0.004649               0 -0.001167\n",
       "3408  pessoas que     0.000282         0.001373               0 -0.001091\n",
       "2731  maioria dos     0.000188         0.001268               0 -0.001080\n",
       "4121     que você     0.001035         0.002113               0 -0.001078\n",
       "4036     não sabe     0.000753         0.001796               0 -0.001043\n",
       "3859   todo mundo     0.000470         0.001479               0 -0.001009\n",
       "3581       de sua     0.000376         0.001373               0 -0.000997\n",
       "3699     sabe que     0.000376         0.001373               0 -0.000997\n",
       "4142      que ser     0.001223         0.002219               0 -0.000996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.not_sexist_bigrams.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SVM with TF of unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with TF of 100 sexist unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with TF of 100 not sexist unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Char quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Word quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Likes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Dislikes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Likes and Dislikes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Likes, Dislikes, Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Bigrams TF. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Ngrams and Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Sexist Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Not Sexist Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Unigrams TFs, Likes, Dislikes, Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with TF of unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with TF of 100 sexist unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with TF of 100 not sexist unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Char quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Word quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Likes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Dislikes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Likes and Dislikes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Likes, Dislikes, Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Bigrams TF. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Ngrams and Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Sexist Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Not Sexist Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Unigrams TFs, Likes, Dislikes, Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with TF of unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with TF of 100 sexist unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with TF of 100 not sexist unigrams. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Char quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Word quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Likes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Dislikes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Likes and Dislikes quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Likes, Dislikes, Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Bigrams TF. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Ngrams and Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Sexist Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Not Sexist Bigrams TFs. Model\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Unigrams TFs, Likes, Dislikes, Chars and Words quantity. Model\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from classifiers.svm import SVM\n",
    "from classifiers.knn import KNN\n",
    "from classifiers.rfc import RFC\n",
    "\n",
    "svm_classifier = SVM()\n",
    "svm_params = dict(gamma=[1.0], C=[10.0])\n",
    "svm_classifier.train_models(svm_params, features)\n",
    "\n",
    "knn_classifier = KNN()\n",
    "knn_params = dict(n_neighbors=[3, 5, 11, 19],\n",
    "                  weights=['uniform', 'distance'],\n",
    "                  metric=['euclidean', 'manhattan'])\n",
    "knn_classifier.train_models(knn_params, features)\n",
    "\n",
    "rfc_classifier = RFC()\n",
    "rfc_params = { \n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['entropy']\n",
    "}\n",
    "rfc_classifier.train_models(rfc_params, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> SVM with Unigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99080 \t 0.86832\n",
      "recall\t\t 0.86283 \t 0.99120\n",
      "f1\t\t 0.92236 \t 0.92568\n",
      "\n",
      ">>>> SVM with TF to 100 sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97812 \t 0.80696\n",
      "recall\t\t 0.78583 \t 0.98065\n",
      "f1\t\t 0.87136 \t 0.88530\n",
      "\n",
      ">>>> SVM with TF to 100 not sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.96108 \t 0.80386\n",
      "recall\t\t 0.78503 \t 0.96510\n",
      "f1\t\t 0.86407 \t 0.87707\n",
      "\n",
      ">>>> SVM with Char quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.63246 \t 0.64083\n",
      "recall\t\t 0.72433 \t 0.53842\n",
      "f1\t\t 0.67519 \t 0.58499\n",
      "\n",
      ">>>> SVM with Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.57593 \t 0.57259\n",
      "recall\t\t 0.70882 \t 0.42757\n",
      "f1\t\t 0.63545 \t 0.48943\n",
      "\n",
      ">>>> SVM with Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.79167 \t 0.79814\n",
      "recall\t\t 0.82380 \t 0.76217\n",
      "f1\t\t 0.80729 \t 0.77958\n",
      "\n",
      ">>>> SVM with Likes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.59971 \t 0.56191\n",
      "recall\t\t 0.60160 \t 0.55982\n",
      "f1\t\t 0.60056 \t 0.56076\n",
      "\n",
      ">>>> SVM with Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.62499 \t 0.55750\n",
      "recall\t\t 0.52781 \t 0.65249\n",
      "f1\t\t 0.57222 \t 0.60121\n",
      "\n",
      ">>>> SVM with Likes and Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.74131 \t 0.63572\n",
      "recall\t\t 0.59706 \t 0.77097\n",
      "f1\t\t 0.66116 \t 0.69669\n",
      "\n",
      ">>>> SVM with Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.98208 \t 0.97895\n",
      "recall\t\t 0.98075 \t 0.98035\n",
      "f1\t\t 0.98140 \t 0.97964\n",
      "\n",
      ">>>> SVM with Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.88083 \t 0.98572\n",
      "recall\t\t 0.98877 \t 0.85308\n",
      "f1\t\t 0.93165 \t 0.91456\n",
      "\n",
      ">>>> SVM with Seixst Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.77928 \t 0.98500\n",
      "recall\t\t 0.99037 \t 0.69208\n",
      "f1\t\t 0.87219 \t 0.81281\n",
      "\n",
      ">>>> SVM with Not Sexist Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.82517 \t 0.99430\n",
      "recall\t\t 0.99599 \t 0.76804\n",
      "f1\t\t 0.90248 \t 0.86639\n",
      "\n",
      ">>>> SVM with Ngrams and Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99325 \t 0.94114\n",
      "recall\t\t 0.94332 \t 0.99296\n",
      "f1\t\t 0.96762 \t 0.96634\n",
      "\n",
      ">>>> SVM with Unigrams TFs, Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99786 \t 0.99532\n",
      "recall\t\t 0.99572 \t 0.99765\n",
      "f1\t\t 0.99679 \t 0.99649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_classifier.report_results(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> KNN with Unigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97126 \t 0.87728\n",
      "recall\t\t 0.87594 \t 0.97155\n",
      "f1\t\t 0.92109 \t 0.92197\n",
      "\n",
      ">>>> KNN with TF to 100 sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.77470 \t 0.97960\n",
      "recall\t\t 0.98690 \t 0.68475\n",
      "f1\t\t 0.86793 \t 0.80576\n",
      "\n",
      ">>>> KNN with TF to 100 not sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.77443 \t 0.97619\n",
      "recall\t\t 0.98476 \t 0.68504\n",
      "f1\t\t 0.86696 \t 0.80490\n",
      "\n",
      ">>>> KNN with Char quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.59060 \t 0.57660\n",
      "recall\t\t 0.67353 \t 0.48768\n",
      "f1\t\t 0.62925 \t 0.52826\n",
      "\n",
      ">>>> KNN with Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.55990 \t 0.53671\n",
      "recall\t\t 0.66043 \t 0.43079\n",
      "f1\t\t 0.60591 \t 0.47772\n",
      "\n",
      ">>>> KNN with Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.59610 \t 0.57440\n",
      "recall\t\t 0.65214 \t 0.51496\n",
      "f1\t\t 0.62269 \t 0.54277\n",
      "\n",
      ">>>> KNN with Likes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.57664 \t 0.52225\n",
      "recall\t\t 0.50455 \t 0.59384\n",
      "f1\t\t 0.53813 \t 0.55571\n",
      "\n",
      ">>>> KNN with Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.58672 \t 0.51915\n",
      "recall\t\t 0.44706 \t 0.65455\n",
      "f1\t\t 0.50720 \t 0.57890\n",
      "\n",
      ">>>> KNN with Likes and Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.62697 \t 0.56604\n",
      "recall\t\t 0.55535 \t 0.63666\n",
      "f1\t\t 0.58873 \t 0.59908\n",
      "\n",
      ">>>> KNN with Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99669 \t 0.96295\n",
      "recall\t\t 0.96497 \t 0.99648\n",
      "f1\t\t 0.98056 \t 0.97941\n",
      "\n",
      ">>>> KNN with Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.98846 \t 0.85741\n",
      "recall\t\t 0.84973 \t 0.98915\n",
      "f1\t\t 0.91378 \t 0.91852\n",
      "\n",
      ">>>> KNN with Seixst Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.77961 \t 0.98662\n",
      "recall\t\t 0.99144 \t 0.69238\n",
      "f1\t\t 0.87282 \t 0.81358\n",
      "\n",
      ">>>> KNN with Not Sexist Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.83030 \t 0.99285\n",
      "recall\t\t 0.99492 \t 0.77654\n",
      "f1\t\t 0.90511 \t 0.87127\n",
      "\n",
      ">>>> KNN with Ngrams and Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99660 \t 0.93901\n",
      "recall\t\t 0.94091 \t 0.99648\n",
      "f1\t\t 0.96794 \t 0.96687\n",
      "\n",
      ">>>> KNN with Unigrams TFs, Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.66972 \t 0.57767\n",
      "recall\t\t 0.52139 \t 0.71789\n",
      "f1\t\t 0.58623 \t 0.64015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_classifier.report_results(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> RFC with Unigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97384 \t 0.80506\n",
      "recall\t\t 0.78396 \t 0.97683\n",
      "f1\t\t 0.86847 \t 0.88258\n",
      "\n",
      ">>>> RFC with TF to 100 sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.98751 \t 0.74811\n",
      "recall\t\t 0.69572 \t 0.99032\n",
      "f1\t\t 0.81619 \t 0.85229\n",
      "\n",
      ">>>> RFC with TF to 100 not sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.96120 \t 0.72965\n",
      "recall\t\t 0.67193 \t 0.97009\n",
      "f1\t\t 0.79070 \t 0.83278\n",
      "\n",
      ">>>> RFC with Char quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.55230 \t 0.57777\n",
      "recall\t\t 0.81711 \t 0.27361\n",
      "f1\t\t 0.65904 \t 0.37100\n",
      "\n",
      ">>>> RFC with Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.54717 \t 0.56312\n",
      "recall\t\t 0.81845 \t 0.25689\n",
      "f1\t\t 0.65580 \t 0.35244\n",
      "\n",
      ">>>> RFC with Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.55380 \t 0.59023\n",
      "recall\t\t 0.83342 \t 0.26334\n",
      "f1\t\t 0.66538 \t 0.36387\n",
      "\n",
      ">>>> RFC with Likes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.57858 \t 0.54975\n",
      "recall\t\t 0.62647 \t 0.49971\n",
      "f1\t\t 0.60149 \t 0.52342\n",
      "\n",
      ">>>> RFC with Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.60644 \t 0.55044\n",
      "recall\t\t 0.54358 \t 0.61290\n",
      "f1\t\t 0.57318 \t 0.57991\n",
      "\n",
      ">>>> RFC with Likes and Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.59103 \t 0.56660\n",
      "recall\t\t 0.64171 \t 0.51320\n",
      "f1\t\t 0.61528 \t 0.53850\n",
      "\n",
      ">>>> RFC with Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.60725 \t 0.58148\n",
      "recall\t\t 0.64251 \t 0.54428\n",
      "f1\t\t 0.62430 \t 0.56214\n",
      "\n",
      ">>>> RFC with Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.83642 \t 0.97996\n",
      "recall\t\t 0.98529 \t 0.78827\n",
      "f1\t\t 0.90470 \t 0.87355\n",
      "\n",
      ">>>> RFC with Seixst Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.71382 \t 0.95160\n",
      "recall\t\t 0.97353 \t 0.57155\n",
      "f1\t\t 0.82364 \t 0.71390\n",
      "\n",
      ">>>> RFC with Not Sexist Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.98021 \t 0.76049\n",
      "recall\t\t 0.71711 \t 0.98416\n",
      "f1\t\t 0.82815 \t 0.85794\n",
      "\n",
      ">>>> RFC with Ngrams and Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.98395 \t 0.87091\n",
      "recall\t\t 0.86684 \t 0.98446\n",
      "f1\t\t 0.92165 \t 0.92418\n",
      "\n",
      ">>>> RFC with Unigrams TFs, Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97622 \t 0.80790\n",
      "recall\t\t 0.78743 \t 0.97889\n",
      "f1\t\t 0.87156 \t 0.88513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_classifier.report_results(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def get_scores(model):\n",
    "    scores = []\n",
    "    for i in range(0,10):\n",
    "        scores.append(model.cv_results_[f'split{i}_test_score'][0])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_scores = {\n",
    "    'tf_unigrams': get_scores(svm_classifier.model_tf_unigrams),\n",
    "    'tf_sexist_unigrams': get_scores(svm_classifier.model_tf_sexist_unigrams),\n",
    "    'tf_not_sexist_unigrams': get_scores(svm_classifier.model_tf_not_sexist_unigrams),\n",
    "    'char_qty': get_scores(svm_classifier.model_char_qty),\n",
    "    'word_qty': get_scores(svm_classifier.model_word_qty),\n",
    "    'likes_qty': get_scores(svm_classifier.model_likes_qty),\n",
    "    'dislikes_qty': get_scores(svm_classifier.model_dislikes_qty),\n",
    "    'likes_dislikes_qty': get_scores(svm_classifier.model_likes_dislikes_qty),\n",
    "    'likes_dislikes_chars_words_qty': get_scores(svm_classifier.model_likes_dislikes_chars_words_qty),\n",
    "    'tf_unigrams_likes_dislikes_chars_words': get_scores(svm_classifier.model_tf_unigrams_likes_dislikes_chars_words),\n",
    "    'tf_bigrams': get_scores(svm_classifier.model_tf_bigrams),\n",
    "    'tf_sexist_bigrams': get_scores(svm_classifier.model_tf_sexist_bigrams),\n",
    "    'tf_not_sexist_bigrams': get_scores(svm_classifier.model_tf_not_sexist_bigrams),\n",
    "    'tf_unigrams_bigrams': get_scores(svm_classifier.model_tf_unigrams_bigrams),\n",
    "}\n",
    "\n",
    "knn_model_scores = {\n",
    "    'tf_unigrams': get_scores(knn_classifier.model_tf_unigrams),\n",
    "    'tf_sexist_unigrams': get_scores(knn_classifier.model_tf_sexist_unigrams),\n",
    "    'tf_not_sexist_unigrams': get_scores(knn_classifier.model_tf_not_sexist_unigrams),\n",
    "    'char_qty': get_scores(knn_classifier.model_char_qty),\n",
    "    'word_qty': get_scores(knn_classifier.model_word_qty),\n",
    "    'likes_qty': get_scores(knn_classifier.model_likes_qty),\n",
    "    'dislikes_qty': get_scores(knn_classifier.model_dislikes_qty),\n",
    "    'likes_dislikes_qty': get_scores(knn_classifier.model_likes_dislikes_qty),\n",
    "    'likes_dislikes_chars_words_qty': get_scores(knn_classifier.model_likes_dislikes_chars_words_qty),\n",
    "    'tf_unigrams_likes_dislikes_chars_words': get_scores(knn_classifier.model_tf_unigrams_likes_dislikes_chars_words),\n",
    "    'tf_bigrams': get_scores(knn_classifier.model_tf_bigrams),\n",
    "    'tf_sexist_bigrams': get_scores(knn_classifier.model_tf_sexist_bigrams),\n",
    "    'tf_not_sexist_bigrams': get_scores(knn_classifier.model_tf_not_sexist_bigrams),\n",
    "    'tf_unigrams_bigrams': get_scores(knn_classifier.model_tf_unigrams_bigrams),\n",
    "}\n",
    "\n",
    "rfc_model_scores = {\n",
    "    'tf_unigrams': get_scores(rfc_classifier.model_tf_unigrams),\n",
    "    'tf_sexist_unigrams': get_scores(rfc_classifier.model_tf_sexist_unigrams),\n",
    "    'tf_not_sexist_unigrams': get_scores(rfc_classifier.model_tf_not_sexist_unigrams),\n",
    "    'char_qty': get_scores(rfc_classifier.model_char_qty),\n",
    "    'word_qty': get_scores(rfc_classifier.model_word_qty),\n",
    "    'likes_qty': get_scores(rfc_classifier.model_likes_qty),\n",
    "    'dislikes_qty': get_scores(rfc_classifier.model_dislikes_qty),\n",
    "    'likes_dislikes_qty': get_scores(rfc_classifier.model_likes_dislikes_qty),\n",
    "    'likes_dislikes_chars_words_qty': get_scores(rfc_classifier.model_likes_dislikes_chars_words_qty),\n",
    "    'tf_unigrams_likes_dislikes_chars_words': get_scores(rfc_classifier.model_tf_unigrams_likes_dislikes_chars_words),\n",
    "    'tf_bigrams': get_scores(rfc_classifier.model_tf_bigrams),\n",
    "    'tf_sexist_bigrams': get_scores(rfc_classifier.model_tf_sexist_bigrams),\n",
    "    'tf_not_sexist_bigrams': get_scores(rfc_classifier.model_tf_not_sexist_bigrams),\n",
    "    'tf_unigrams_bigrams': get_scores(rfc_classifier.model_tf_unigrams_bigrams),\n",
    "}\n",
    "\n",
    "bert_model_scores = [\n",
    "    0.571069182389937,\n",
    "    0.45852187028657615,\n",
    "    0.5364583333333334,\n",
    "    0.5258964143426295,\n",
    "    0.5313351498637601,\n",
    "    0.4828571428571429,\n",
    "    0.43333333333333335,\n",
    "    0.5463659147869674,\n",
    "    0.5493333333333332,\n",
    "    0.5195822454308094\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bert_model_scores',\n",
    "           'svm_tf_unigrams',\n",
    "           'svm_tf_bigrams',\n",
    "           'svm_tf_unigrams_bigrams',\n",
    "           'svm_likes_dislikes_chars_words_qty',\n",
    "           'svm_tf_unigrams_likes_dislikes_chars_words',\n",
    "           'knn_tf_unigrams',\n",
    "           'knn_likes_dislikes_chars_words_qty',\n",
    "           'knn_tf_bigrams',\n",
    "           'knn_tf_unigrams_bigrams',\n",
    "           'rfc_tf_unigrams_bigrams',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "def select_values(l):\n",
    "    if 'svm' in l:\n",
    "        return svm_model_scores[l.replace('svm_','')]\n",
    "    if 'knn' in l:\n",
    "        return knn_model_scores[l.replace('knn_','')]\n",
    "    if 'rfc' in l:\n",
    "        return rfc_model_scores[l.replace('rfc_','')]   \n",
    "    if 'bert' in l:\n",
    "        return bert_model_scores\n",
    "    if 'baseline_svm' in l:\n",
    "        return baseline_model_scores['svm']\n",
    "    if 'baseline_lr' in l:\n",
    "        return baseline_model_scores['lr']\n",
    "i = 0\n",
    "for l in columns:\n",
    "    results.append([])\n",
    "    values_y = select_values(l)\n",
    "    for c in columns:\n",
    "        values_x = select_values(c)\n",
    "        if values_x == values_y:\n",
    "            results[i].append((0, 0))\n",
    "        else:\n",
    "            test_stat, test_p = wilcoxon(values_y, values_x)\n",
    "            results[i].append((test_stat, test_p))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_model_scores</th>\n",
       "      <th>svm_tf_unigrams</th>\n",
       "      <th>svm_tf_bigrams</th>\n",
       "      <th>svm_tf_unigrams_bigrams</th>\n",
       "      <th>svm_likes_dislikes_chars_words_qty</th>\n",
       "      <th>svm_tf_unigrams_likes_dislikes_chars_words</th>\n",
       "      <th>knn_tf_unigrams</th>\n",
       "      <th>knn_likes_dislikes_chars_words_qty</th>\n",
       "      <th>knn_tf_bigrams</th>\n",
       "      <th>knn_tf_unigrams_bigrams</th>\n",
       "      <th>rfc_tf_unigrams_bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert_model_scores</th>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(13.0, 0.13941397332153205)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_tf_unigrams</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(26.0, 0.8784817434328712)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_tf_bigrams</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(26.0, 0.8784817434328712)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_tf_unigrams_bigrams</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(3.0, 0.012515318690073973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_likes_dislikes_chars_words_qty</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_tf_unigrams_likes_dislikes_chars_words</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tf_unigrams</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_likes_dislikes_chars_words_qty</th>\n",
       "      <td>(13.0, 0.13941397332153205)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tf_bigrams</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(21.0, 0.5076243443095237)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tf_unigrams_bigrams</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(21.0, 0.5076243443095237)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfc_tf_unigrams_bigrams</th>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(3.0, 0.012515318690073973)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0.0, 0.005062032126267864)</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      bert_model_scores  \\\n",
       "bert_model_scores                                                (0, 0)   \n",
       "svm_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty          (13.0, 0.13941397332153205)   \n",
       "knn_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                                        svm_tf_unigrams  \\\n",
       "bert_model_scores                           (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                                                  (0, 0)   \n",
       "svm_tf_bigrams                               (26.0, 0.8784817434328712)   \n",
       "svm_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                                         svm_tf_bigrams  \\\n",
       "bert_model_scores                           (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                              (26.0, 0.8784817434328712)   \n",
       "svm_tf_bigrams                                                   (0, 0)   \n",
       "svm_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                                svm_tf_unigrams_bigrams  \\\n",
       "bert_model_scores                           (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                                          (0, 0)   \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                     (3.0, 0.012515318690073973)   \n",
       "\n",
       "                                           svm_likes_dislikes_chars_words_qty  \\\n",
       "bert_model_scores                                 (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                                   (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                                    (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                           (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty                                     (0, 0)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words        (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                                   (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty                (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                                    (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                           (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                           (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                           svm_tf_unigrams_likes_dislikes_chars_words  \\\n",
       "bert_model_scores                                         (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                                           (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                                            (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                                   (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty                        (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words                                     (0, 0)   \n",
       "knn_tf_unigrams                                           (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty                        (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                                            (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                                   (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                                   (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                                        knn_tf_unigrams  \\\n",
       "bert_model_scores                           (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                                                  (0, 0)   \n",
       "knn_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                           knn_likes_dislikes_chars_words_qty  \\\n",
       "bert_model_scores                                 (13.0, 0.13941397332153205)   \n",
       "svm_tf_unigrams                                   (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                                    (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                           (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty                (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words        (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                                   (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty                                     (0, 0)   \n",
       "knn_tf_bigrams                                    (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams_bigrams                           (0.0, 0.005062032126267864)   \n",
       "rfc_tf_unigrams_bigrams                           (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                                         knn_tf_bigrams  \\\n",
       "bert_model_scores                           (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                                                   (0, 0)   \n",
       "knn_tf_unigrams_bigrams                      (21.0, 0.5076243443095237)   \n",
       "rfc_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                                knn_tf_unigrams_bigrams  \\\n",
       "bert_model_scores                           (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "svm_tf_bigrams                              (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)   \n",
       "knn_tf_unigrams                             (0.0, 0.005062032126267864)   \n",
       "knn_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)   \n",
       "knn_tf_bigrams                               (21.0, 0.5076243443095237)   \n",
       "knn_tf_unigrams_bigrams                                          (0, 0)   \n",
       "rfc_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)   \n",
       "\n",
       "                                                rfc_tf_unigrams_bigrams  \n",
       "bert_model_scores                           (0.0, 0.005062032126267864)  \n",
       "svm_tf_unigrams                             (0.0, 0.005062032126267864)  \n",
       "svm_tf_bigrams                              (0.0, 0.005062032126267864)  \n",
       "svm_tf_unigrams_bigrams                     (3.0, 0.012515318690073973)  \n",
       "svm_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)  \n",
       "svm_tf_unigrams_likes_dislikes_chars_words  (0.0, 0.005062032126267864)  \n",
       "knn_tf_unigrams                             (0.0, 0.005062032126267864)  \n",
       "knn_likes_dislikes_chars_words_qty          (0.0, 0.005062032126267864)  \n",
       "knn_tf_bigrams                              (0.0, 0.005062032126267864)  \n",
       "knn_tf_unigrams_bigrams                     (0.0, 0.005062032126267864)  \n",
       "rfc_tf_unigrams_bigrams                                          (0, 0)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, columns=columns, index=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_model_scores',\n",
       " 'svm_tf_unigrams',\n",
       " 'svm_tf_bigrams',\n",
       " 'svm_tf_unigrams_bigrams',\n",
       " 'svm_likes_dislikes_chars_words_qty',\n",
       " 'svm_tf_unigrams_likes_dislikes_chars_words',\n",
       " 'knn_tf_unigrams',\n",
       " 'knn_likes_dislikes_chars_words_qty',\n",
       " 'knn_bigrams',\n",
       " 'knn_unigrams_bigrams',\n",
       " 'rfc_unigrams_bigrams']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KNN' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a9d9b19b5fcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknn_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KNN' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "knn_classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=KNeighborsClassifier(), n_jobs=12,\n",
       "             param_grid={'metric': ['euclidean', 'manhattan'],\n",
       "                         'n_neighbors': [3, 5, 11, 19],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.model_tf_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scoring': 'f1',\n",
       " 'estimator': KNeighborsClassifier(),\n",
       " 'n_jobs': 12,\n",
       " 'refit': True,\n",
       " 'cv': StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.2,\n",
       "             train_size=None),\n",
       " 'verbose': 0,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'error_score': nan,\n",
       " 'return_train_score': False,\n",
       " 'param_grid': {'n_neighbors': [3, 5, 11, 19],\n",
       "  'weights': ['uniform', 'distance'],\n",
       "  'metric': ['euclidean', 'manhattan']},\n",
       " 'multimetric_': False,\n",
       " 'best_index_': 9,\n",
       " 'best_score_': 0.7970995007583548,\n",
       " 'best_params_': {'metric': 'manhattan',\n",
       "  'n_neighbors': 3,\n",
       "  'weights': 'distance'},\n",
       " 'best_estimator_': KNeighborsClassifier(metric='manhattan', n_neighbors=3, weights='distance'),\n",
       " 'refit_time_': 0.00932765007019043,\n",
       " 'scorer_': make_scorer(f1_score, average=binary),\n",
       " 'cv_results_': {'mean_fit_time': array([0.02597923, 0.03327157, 0.04386549, 0.03305533, 0.03286896,\n",
       "         0.02618849, 0.03169377, 0.02937942, 0.02656765, 0.03200812,\n",
       "         0.02711742, 0.03788321, 0.0301183 , 0.03362391, 0.026756  ,\n",
       "         0.0261306 ]),\n",
       "  'std_fit_time': array([0.01401103, 0.02521459, 0.02028561, 0.0095027 , 0.00978657,\n",
       "         0.00875136, 0.01047339, 0.01330343, 0.00782848, 0.01255156,\n",
       "         0.01226451, 0.0157605 , 0.00898205, 0.00883437, 0.0092047 ,\n",
       "         0.01307562]),\n",
       "  'mean_score_time': array([0.43496993, 0.23332088, 0.32805891, 0.23453014, 0.3484591 ,\n",
       "         0.24000111, 0.32782674, 0.2657994 , 2.47941828, 2.48262105,\n",
       "         2.75406506, 2.45612462, 2.39515665, 2.44813061, 2.48592279,\n",
       "         1.77469239]),\n",
       "  'std_score_time': array([0.10783191, 0.07916719, 0.07868653, 0.08270785, 0.07494371,\n",
       "         0.06204946, 0.05210776, 0.05520947, 0.16822966, 0.29975897,\n",
       "         0.21375336, 0.18823709, 0.10685362, 0.2347624 , 0.18152304,\n",
       "         0.435138  ]),\n",
       "  'param_metric': masked_array(data=['euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                     'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                     'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                     'manhattan', 'manhattan', 'manhattan', 'manhattan'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_neighbors': masked_array(data=[3, 3, 5, 5, 11, 11, 19, 19, 3, 3, 5, 5, 11, 11, 19, 19],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                     'uniform', 'distance', 'uniform', 'distance',\n",
       "                     'uniform', 'distance', 'uniform', 'distance',\n",
       "                     'uniform', 'distance', 'uniform', 'distance'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'},\n",
       "   {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'},\n",
       "   {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'},\n",
       "   {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'},\n",
       "   {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'},\n",
       "   {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'},\n",
       "   {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'uniform'},\n",
       "   {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'distance'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'},\n",
       "   {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}],\n",
       "  'split0_test_score': array([0.7875969 , 0.78582435, 0.79356568, 0.79575597, 0.7545582 ,\n",
       "         0.75242047, 0.7278798 , 0.73409462, 0.81081081, 0.81081081,\n",
       "         0.7946027 , 0.7994012 , 0.78378378, 0.78666667, 0.75120385,\n",
       "         0.77934272]),\n",
       "  'split1_test_score': array([0.77388535, 0.78425197, 0.77241379, 0.77197802, 0.72413793,\n",
       "         0.73758865, 0.70791367, 0.72364672, 0.79186228, 0.80370943,\n",
       "         0.77866667, 0.78552279, 0.78284182, 0.78975741, 0.76294278,\n",
       "         0.77883311]),\n",
       "  'split2_test_score': array([0.76268861, 0.76398363, 0.76689655, 0.77384196, 0.74220963,\n",
       "         0.74333801, 0.71764706, 0.72543353, 0.77997365, 0.78157895,\n",
       "         0.77112135, 0.77607362, 0.7511592 , 0.76335878, 0.77384196,\n",
       "         0.7755102 ]),\n",
       "  'split3_test_score': array([0.79937304, 0.79750779, 0.77358491, 0.7751938 , 0.74380165,\n",
       "         0.73856209, 0.70945946, 0.72368421, 0.80305344, 0.80674847,\n",
       "         0.7804878 , 0.78115502, 0.77639752, 0.7800312 , 0.7483871 ,\n",
       "         0.76629571]),\n",
       "  'split4_test_score': array([0.80125196, 0.80745342, 0.76433121, 0.76582278, 0.71641791,\n",
       "         0.72487644, 0.70748299, 0.71932773, 0.80373832, 0.80989181,\n",
       "         0.78516229, 0.7820711 , 0.77747253, 0.78522572, 0.74919614,\n",
       "         0.76205788]),\n",
       "  'split5_test_score': array([0.77093207, 0.76995305, 0.77091907, 0.77506775, 0.73038516,\n",
       "         0.74053296, 0.72069465, 0.7311522 , 0.78890601, 0.78825348,\n",
       "         0.79255319, 0.79260238, 0.76650564, 0.77795276, 0.72878536,\n",
       "         0.75483871]),\n",
       "  'split6_test_score': array([0.80314961, 0.81493002, 0.79370079, 0.80559876, 0.75986842,\n",
       "         0.77867528, 0.71477663, 0.73400673, 0.81733746, 0.82874618,\n",
       "         0.81832061, 0.82956259, 0.79425837, 0.81377152, 0.74706868,\n",
       "         0.78119935]),\n",
       "  'split7_test_score': array([0.74044796, 0.75195822, 0.76006441, 0.77358491, 0.71890971,\n",
       "         0.74876847, 0.71477663, 0.74086379, 0.78421702, 0.77931904,\n",
       "         0.78369906, 0.79569892, 0.75693312, 0.78095238, 0.75125209,\n",
       "         0.77221325]),\n",
       "  'split8_test_score': array([0.77316294, 0.78233438, 0.78151261, 0.79172414, 0.72305141,\n",
       "         0.74110032, 0.68048359, 0.70469799, 0.77725118, 0.78627145,\n",
       "         0.76923077, 0.77300613, 0.74760383, 0.76461295, 0.7001675 ,\n",
       "         0.73289902]),\n",
       "  'split9_test_score': array([0.77220077, 0.77278562, 0.775     , 0.77708978, 0.71380471,\n",
       "         0.72786885, 0.69296741, 0.70568562, 0.77363184, 0.7756654 ,\n",
       "         0.78284182, 0.78295606, 0.74836601, 0.76236045, 0.70967742,\n",
       "         0.73563218]),\n",
       "  'mean_test_score': array([0.77846892, 0.78309824, 0.7751989 , 0.78056579, 0.73271447,\n",
       "         0.74337316, 0.70940819, 0.72425931, 0.7930782 , 0.7970995 ,\n",
       "         0.78566863, 0.78980498, 0.76853218, 0.78046898, 0.74225229,\n",
       "         0.76388221]),\n",
       "  'std_test_score': array([0.01867719, 0.01854085, 0.0107904 , 0.01199215, 0.01553594,\n",
       "         0.01417588, 0.01306514, 0.01126498, 0.01419116, 0.01643746,\n",
       "         0.01327851, 0.01544652, 0.01589385, 0.01461239, 0.02170205,\n",
       "         0.01678099]),\n",
       "  'rank_test_score': array([ 8,  5,  9,  6, 14, 12, 16, 15,  2,  1,  4,  3, 10,  7, 13, 11])},\n",
       " 'n_splits_': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.model_tf_unigrams.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scoring': 'f1',\n",
       " 'estimator': RandomForestClassifier(),\n",
       " 'n_jobs': 12,\n",
       " 'refit': True,\n",
       " 'cv': StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.2,\n",
       "             train_size=None),\n",
       " 'verbose': 0,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'error_score': nan,\n",
       " 'return_train_score': False,\n",
       " 'param_grid': {'n_estimators': [200],\n",
       "  'max_features': ['auto'],\n",
       "  'max_depth': [4, 5, 6, 7, 8],\n",
       "  'criterion': ['entropy']},\n",
       " 'multimetric_': False,\n",
       " 'best_index_': 4,\n",
       " 'best_score_': 0.8638480599666533,\n",
       " 'best_params_': {'criterion': 'entropy',\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 200},\n",
       " 'best_estimator_': RandomForestClassifier(criterion='entropy', max_depth=8, n_estimators=200),\n",
       " 'refit_time_': 0.44132161140441895,\n",
       " 'scorer_': make_scorer(f1_score, average=binary),\n",
       " 'cv_results_': {'mean_fit_time': array([0.98905756, 1.08937073, 1.20143616, 1.24455857, 1.1870702 ]),\n",
       "  'std_fit_time': array([0.19201289, 0.08400931, 0.09635543, 0.16945437, 0.20167996]),\n",
       "  'mean_score_time': array([0.07483943, 0.07655151, 0.07629387, 0.06598628, 0.03824608]),\n",
       "  'std_score_time': array([0.01245535, 0.0189705 , 0.02419485, 0.02801984, 0.01100953]),\n",
       "  'param_criterion': masked_array(data=['entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "               mask=[False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_max_depth': masked_array(data=[4, 5, 6, 7, 8],\n",
       "               mask=[False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto'],\n",
       "               mask=[False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_estimators': masked_array(data=[200, 200, 200, 200, 200],\n",
       "               mask=[False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'criterion': 'entropy',\n",
       "    'max_depth': 4,\n",
       "    'max_features': 'auto',\n",
       "    'n_estimators': 200},\n",
       "   {'criterion': 'entropy',\n",
       "    'max_depth': 5,\n",
       "    'max_features': 'auto',\n",
       "    'n_estimators': 200},\n",
       "   {'criterion': 'entropy',\n",
       "    'max_depth': 6,\n",
       "    'max_features': 'auto',\n",
       "    'n_estimators': 200},\n",
       "   {'criterion': 'entropy',\n",
       "    'max_depth': 7,\n",
       "    'max_features': 'auto',\n",
       "    'n_estimators': 200},\n",
       "   {'criterion': 'entropy',\n",
       "    'max_depth': 8,\n",
       "    'max_features': 'auto',\n",
       "    'n_estimators': 200}],\n",
       "  'split0_test_score': array([0.86011905, 0.86350148, 0.86518519, 0.86350148, 0.87096774]),\n",
       "  'split1_test_score': array([0.85798817, 0.8562963 , 0.8562963 , 0.86176471, 0.85967504]),\n",
       "  'split2_test_score': array([0.86607143, 0.86478455, 0.86607143, 0.86607143, 0.86607143]),\n",
       "  'split3_test_score': array([0.86775632, 0.87444609, 0.87610619, 0.87776141, 0.8774003 ]),\n",
       "  'split4_test_score': array([0.86865672, 0.87703704, 0.87537092, 0.87905605, 0.88365243]),\n",
       "  'split5_test_score': array([0.86646884, 0.85457271, 0.85628743, 0.85799701, 0.85799701]),\n",
       "  'split6_test_score': array([0.85201794, 0.84464555, 0.8502994 , 0.86135693, 0.85840708]),\n",
       "  'split7_test_score': array([0.84984985, 0.85628743, 0.85799701, 0.86309524, 0.86309524]),\n",
       "  'split8_test_score': array([0.82896764, 0.82896764, 0.82769231, 0.82534776, 0.82896764]),\n",
       "  'split9_test_score': array([0.86853767, 0.86969253, 0.8722467 , 0.86969253, 0.8722467 ]),\n",
       "  'mean_test_score': array([0.85864336, 0.85902313, 0.86035529, 0.86256446, 0.86384806]),\n",
       "  'std_test_score': array([0.01184104, 0.01369024, 0.01370235, 0.01405429, 0.01414394]),\n",
       "  'rank_test_score': array([5, 4, 3, 2, 1])},\n",
       " 'n_splits_': 10}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_classifier.model_tf_unigrams.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
