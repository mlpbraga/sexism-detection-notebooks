{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from modules.dataframe import Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>votes</th>\n",
       "      <th>avg</th>\n",
       "      <th>std</th>\n",
       "      <th>label</th>\n",
       "      <th>char-qty</th>\n",
       "      <th>word-qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489</td>\n",
       "      <td>MUITO MAIS LEGAL  RRSRSRRSRSRS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>Canhão de guerra.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2574</td>\n",
       "      <td>femi o que?</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>951</td>\n",
       "      <td>Concordo plenamente Jaqueline!! Outro dia ouvi...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2520</td>\n",
       "      <td>Feminista é uma mulher encalhada que precisa d...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>55</td>\n",
       "      <td>Brigue esquisitinha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>3858</td>\n",
       "      <td>Pois é, todo o bozopata é assim! Depois que pe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>3984</td>\n",
       "      <td>Será que ninguém tem coragem de enfrentar algu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>790</td>\n",
       "      <td>Perfeito!</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>2850</td>\n",
       "      <td>Impressão sua, a diferença é que agora você vê...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3571 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id                                            content  likes  \\\n",
       "0           1489                     MUITO MAIS LEGAL  RRSRSRRSRSRS    2.0   \n",
       "1            273                                 Canhão de guerra.     2.0   \n",
       "2           2574                                        femi o que?   10.0   \n",
       "3            951  Concordo plenamente Jaqueline!! Outro dia ouvi...   20.0   \n",
       "4           2520  Feminista é uma mulher encalhada que precisa d...   11.0   \n",
       "...          ...                                                ...    ...   \n",
       "3566          55                                Brigue esquisitinha    0.0   \n",
       "3567        3858  Pois é, todo o bozopata é assim! Depois que pe...    3.0   \n",
       "3568        3984  Será que ninguém tem coragem de enfrentar algu...    0.0   \n",
       "3569         790                                          Perfeito!    2.0   \n",
       "3570        2850  Impressão sua, a diferença é que agora você vê...    4.0   \n",
       "\n",
       "      dislikes  votes       avg      std  label  char-qty  word-qty  \n",
       "0          0.0      2  0.000000  0.00000      0        30         5  \n",
       "1          4.0      2  1.000000  0.00000      1        18         4  \n",
       "2         11.0      2  1.000000  0.00000      1        11         3  \n",
       "3          0.0      3  0.666667  0.57735      1       161        27  \n",
       "4         11.0      3  1.000000  0.00000      1        66        11  \n",
       "...        ...    ...       ...      ...    ...       ...       ...  \n",
       "3566       1.0      3  0.666667  0.57735      1        19         2  \n",
       "3567       0.0      3  0.333333  0.57735      0       192        35  \n",
       "3568       0.0      1  0.000000      NaN      0       368        60  \n",
       "3569       2.0      3  0.333333  0.57735      0         9         1  \n",
       "3570       0.0      3  0.333333  0.57735      0       270        44  \n",
       "\n",
       "[3571 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_comments = pd.read_csv('data/labeled-comments.csv')\n",
    "labeled_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Dataset fields description</b>\n",
    "    <hline/>\n",
    "    <p><b>comment_id</b>: unique identifier to each comment from database</p>\n",
    "    <p><b>content</b>: comment text content</p>\n",
    "    <p><b>likes</b>: comment likes quantity</p>\n",
    "    <p><b>dislikes</b>: comment dislikes quantity</p>\n",
    "    <p><b>votes</b>: number of users that labeled the comment</p>\n",
    "    <p><b>avg</b>: average of each vote value to the comment</p>\n",
    "    <p><b>std</b>: standard deviation of each vote value to the comment</p>\n",
    "    <p><b>label</b>: final label assigned to the comment, label 1 represents sexist comments and label 0 represets not sexist comments</p>\n",
    "    <p><b>char-qty</b>: number of characters in the comment </p>\n",
    "    <p><b>word-qty</b>: number of words in the comment</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>votes</th>\n",
       "      <th>avg</th>\n",
       "      <th>std</th>\n",
       "      <th>label</th>\n",
       "      <th>char-qty</th>\n",
       "      <th>word-qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3323.000000</td>\n",
       "      <td>3323.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>2886.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "      <td>3571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1923.082610</td>\n",
       "      <td>15.611496</td>\n",
       "      <td>9.856455</td>\n",
       "      <td>2.534304</td>\n",
       "      <td>0.523321</td>\n",
       "      <td>0.230954</td>\n",
       "      <td>0.523663</td>\n",
       "      <td>140.439373</td>\n",
       "      <td>24.494539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1135.048496</td>\n",
       "      <td>40.102726</td>\n",
       "      <td>41.783877</td>\n",
       "      <td>1.032327</td>\n",
       "      <td>0.420923</td>\n",
       "      <td>0.277073</td>\n",
       "      <td>0.499510</td>\n",
       "      <td>178.984760</td>\n",
       "      <td>27.111817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>988.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1886.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2783.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4283.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7050.000000</td>\n",
       "      <td>819.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment_id        likes     dislikes        votes          avg  \\\n",
       "count  3571.000000  3323.000000  3323.000000  3571.000000  3571.000000   \n",
       "mean   1923.082610    15.611496     9.856455     2.534304     0.523321   \n",
       "std    1135.048496    40.102726    41.783877     1.032327     0.420923   \n",
       "min       4.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "25%     988.500000     2.000000     0.000000     2.000000     0.000000   \n",
       "50%    1886.000000     5.000000     1.000000     3.000000     0.666667   \n",
       "75%    2783.500000    14.000000     6.000000     3.000000     1.000000   \n",
       "max    4283.000000   729.000000  1196.000000     7.000000     1.000000   \n",
       "\n",
       "               std        label     char-qty     word-qty  \n",
       "count  2886.000000  3571.000000  3571.000000  3571.000000  \n",
       "mean      0.230954     0.523663   140.439373    24.494539  \n",
       "std       0.277073     0.499510   178.984760    27.111817  \n",
       "min       0.000000     0.000000     2.000000     1.000000  \n",
       "25%       0.000000     0.000000    47.000000     9.000000  \n",
       "50%       0.000000     1.000000    94.000000    17.000000  \n",
       "75%       0.577350     1.000000   179.000000    32.000000  \n",
       "max       0.577350     1.000000  7050.000000   819.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_comments.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "A visual data analysis is avaliable at https://datastudio.google.com/s/sgO8X7JORMU\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating dataset features and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> No comments without label\n",
      "> Loading local dataframe\n"
     ]
    }
   ],
   "source": [
    "from classifiers.features import Features\n",
    "\n",
    "# The Comments class is responsable for structuring data about\n",
    "# the comments, it's source code can be analized at:\n",
    "# https://github.com/mlpbraga/sexism-detection-notebooks/blob/main/modules/dataframe.py\n",
    "comments = Comments()\n",
    "\n",
    "# The Features class is responsable for turning features structured\n",
    "# above into an python objetect, it's source code can be analized at:\n",
    "# https://github.com/mlpbraga/sexism-detection-notebooks/blob/main/classifiers/features.py\n",
    "features = Features(comments.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>homens</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>ela</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>mulher</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>de</td>\n",
       "      <td>0.040850</td>\n",
       "      <td>0.038762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>elas</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>feia</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>uma</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>as</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>na</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>diz</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>assédio</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>feminismo</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>feministas</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>As</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "3844    mulheres     0.009752         0.006359               0  0.003393\n",
       "3834      homens     0.006732         0.003903               0  0.002829\n",
       "3836         ela     0.007480         0.005013               0  0.002466\n",
       "3845      mulher     0.010040         0.007907               0  0.002133\n",
       "3852          de     0.040850         0.038762               0  0.002089\n",
       "3804        elas     0.002445         0.000471               0  0.001974\n",
       "3795        feia     0.002129         0.000202               0  0.001927\n",
       "3847         uma     0.011996         0.010195               0  0.001801\n",
       "3841          as     0.008803         0.007066               0  0.001737\n",
       "3837          na     0.007882         0.006191               0  0.001691\n",
       "3782         diz     0.001697         0.000303               0  0.001394\n",
       "3798     assédio     0.002244         0.000875               0  0.001369\n",
       "3802   feminismo     0.002388         0.001043               0  0.001345\n",
       "3787  feministas     0.001812         0.000505               0  0.001308\n",
       "3754          As     0.001438         0.000404               0  0.001035"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sexist_words.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>ser</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>sua</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>não</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>comentários</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>em</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>pessoas</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>sobre</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>lei</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>você</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>presidente</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>mundo</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>ainda</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>está</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>seus</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "3830          ser     0.005523         0.007907               0 -0.002384\n",
       "3727       Brasil     0.001093         0.002692               0 -0.001599\n",
       "3758          sua     0.001467         0.003028               0 -0.001561\n",
       "3851          não     0.022007         0.023419               0 -0.001411\n",
       "3372  comentários     0.000345         0.001581               0 -0.001236\n",
       "3839           em     0.008487         0.009690               0 -0.001204\n",
       "3732      pessoas     0.001122         0.002322               0 -0.001200\n",
       "3550        sobre     0.000518         0.001716               0 -0.001198\n",
       "3616          lei     0.000690         0.001817               0 -0.001127\n",
       "3779         você     0.001640         0.002759               0 -0.001119\n",
       "3244   presidente     0.000259         0.001346               0 -0.001087\n",
       "3759        mundo     0.001496         0.002456               0 -0.000960\n",
       "3750        ainda     0.001410         0.002322               0 -0.000912\n",
       "3803         está     0.002417         0.003297               0 -0.000881\n",
       "3548         seus     0.000518         0.001346               0 -0.000828"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.not_sexist_words.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>as mulheres</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>diz que</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>que homens</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>que as</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>que vai</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>os homens</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>mesmo que</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>uma mulher</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>mulheres não</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>mulheres que</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>um homem</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>as feministas</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>são minoria</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>não tem</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>por causa</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "4213    as mulheres     0.009315         0.005705               0  0.003610\n",
       "4203        diz que     0.003670         0.000423               0  0.003247\n",
       "4201     que homens     0.003481         0.000423               0  0.003059\n",
       "4208         que as     0.004610         0.001902               0  0.002709\n",
       "4199        que vai     0.003293         0.000845               0  0.002448\n",
       "4210      os homens     0.005081         0.002853               0  0.002228\n",
       "4198      mesmo que     0.003199         0.001162               0  0.002037\n",
       "4211     uma mulher     0.006022         0.004332               0  0.001690\n",
       "4193   mulheres não     0.002635         0.000951               0  0.001684\n",
       "4195   mulheres que     0.003011         0.001585               0  0.001426\n",
       "4192       um homem     0.002540         0.001162               0  0.001378\n",
       "4172  as feministas     0.001882         0.000528               0  0.001354\n",
       "4157    são minoria     0.001505         0.000211               0  0.001294\n",
       "4207        não tem     0.004610         0.003381               0  0.001230\n",
       "4176      por causa     0.001882         0.000740               0  0.001142"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.sexist_bigrams.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sexist-freq</th>\n",
       "      <th>not-sexist-freq</th>\n",
       "      <th>undefined-freq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>que não</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>ser humano</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>ou não</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>no Brasil</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>todos os</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>as pessoas</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>tem que</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>pessoas que</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>maioria dos</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>que você</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>não sabe</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>todo mundo</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>de sua</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>sabe que</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>que ser</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  sexist-freq  not-sexist-freq  undefined-freq      diff\n",
       "4212      que não     0.007810         0.010037               0 -0.002227\n",
       "3947   ser humano     0.000565         0.002430               0 -0.001865\n",
       "3926       ou não     0.000565         0.002007               0 -0.001443\n",
       "4175    no Brasil     0.001882         0.003170               0 -0.001288\n",
       "4167     todos os     0.001694         0.002958               0 -0.001265\n",
       "4112   as pessoas     0.001035         0.002219               0 -0.001184\n",
       "4202      tem que     0.003481         0.004649               0 -0.001167\n",
       "3408  pessoas que     0.000282         0.001373               0 -0.001091\n",
       "2731  maioria dos     0.000188         0.001268               0 -0.001080\n",
       "4121     que você     0.001035         0.002113               0 -0.001078\n",
       "4036     não sabe     0.000753         0.001796               0 -0.001043\n",
       "3859   todo mundo     0.000470         0.001479               0 -0.001009\n",
       "3581       de sua     0.000376         0.001373               0 -0.000997\n",
       "3699     sabe que     0.000376         0.001373               0 -0.000997\n",
       "4142      que ser     0.001223         0.002219               0 -0.000996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.not_sexist_bigrams.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SVM with TF of unigrams. Model\n",
      "Executing Grid Search to SVM with TF of unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with TF of 100 sexist unigrams. Model\n",
      "Executing Grid Search to SVM with TF of 100 sexist unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with TF of 100 not sexist unigrams. Model\n",
      "Executing Grid Search to SVM with TF of 100 not sexist unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Char quantity. Model\n",
      "Executing Grid Search to SVM with Char quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Word quantity. Model\n",
      "Executing Grid Search to SVM with Word quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Likes quantity. Model\n",
      "Executing Grid Search to SVM with Likes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Dislikes quantity. Model\n",
      "Executing Grid Search to SVM with Dislikes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Likes and Dislikes quantity. Model\n",
      "Executing Grid Search to SVM with Likes and Dislikes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Chars and Words quantity. Model\n",
      "Executing Grid Search to SVM with Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Likes, Dislikes, Chars and Words quantity. Model\n",
      "Executing Grid Search to SVM with Likes, Dislikes, Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Bigrams TF. Model\n",
      "Executing Grid Search to SVM with Bigrams TF.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Ngrams and Bigrams TFs. Model\n",
      "Executing Grid Search to SVM with Ngrams and Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Sexist Bigrams TFs. Model\n",
      "Executing Grid Search to SVM with Sexist Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Not Sexist Bigrams TFs. Model\n",
      "Executing Grid Search to SVM with Not Sexist Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading SVM with Unigrams TFs, Likes, Dislikes, Chars and Words quantity. Model\n",
      "Executing Grid Search to SVM with Unigrams TFs, Likes, Dislikes, Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with TF of unigrams. Model\n",
      "Executing Grid Search to KNN with TF of unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with TF of 100 sexist unigrams. Model\n",
      "Executing Grid Search to KNN with TF of 100 sexist unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with TF of 100 not sexist unigrams. Model\n",
      "Executing Grid Search to KNN with TF of 100 not sexist unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Char quantity. Model\n",
      "Executing Grid Search to KNN with Char quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Word quantity. Model\n",
      "Executing Grid Search to KNN with Word quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Likes quantity. Model\n",
      "Executing Grid Search to KNN with Likes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Dislikes quantity. Model\n",
      "Executing Grid Search to KNN with Dislikes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Likes and Dislikes quantity. Model\n",
      "Executing Grid Search to KNN with Likes and Dislikes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Chars and Words quantity. Model\n",
      "Executing Grid Search to KNN with Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Likes, Dislikes, Chars and Words quantity. Model\n",
      "Executing Grid Search to KNN with Likes, Dislikes, Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Bigrams TF. Model\n",
      "Executing Grid Search to KNN with Bigrams TF.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Ngrams and Bigrams TFs. Model\n",
      "Executing Grid Search to KNN with Ngrams and Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Sexist Bigrams TFs. Model\n",
      "Executing Grid Search to KNN with Sexist Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Not Sexist Bigrams TFs. Model\n",
      "Executing Grid Search to KNN with Not Sexist Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading KNN with Unigrams TFs, Likes, Dislikes, Chars and Words quantity. Model\n",
      "Executing Grid Search to KNN with Unigrams TFs, Likes, Dislikes, Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with TF of unigrams. Model\n",
      "Executing Grid Search to RFC with TF of unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with TF of 100 sexist unigrams. Model\n",
      "Executing Grid Search to RFC with TF of 100 sexist unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with TF of 100 not sexist unigrams. Model\n",
      "Executing Grid Search to RFC with TF of 100 not sexist unigrams.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Char quantity. Model\n",
      "Executing Grid Search to RFC with Char quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Word quantity. Model\n",
      "Executing Grid Search to RFC with Word quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Likes quantity. Model\n",
      "Executing Grid Search to RFC with Likes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Dislikes quantity. Model\n",
      "Executing Grid Search to RFC with Dislikes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Likes and Dislikes quantity. Model\n",
      "Executing Grid Search to RFC with Likes and Dislikes quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Chars and Words quantity. Model\n",
      "Executing Grid Search to RFC with Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Likes, Dislikes, Chars and Words quantity. Model\n",
      "Executing Grid Search to RFC with Likes, Dislikes, Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Bigrams TF. Model\n",
      "Executing Grid Search to RFC with Bigrams TF.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Ngrams and Bigrams TFs. Model\n",
      "Executing Grid Search to RFC with Ngrams and Bigrams TFs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Sexist Bigrams TFs. Model\n",
      "Executing Grid Search to RFC with Sexist Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Not Sexist Bigrams TFs. Model\n",
      "Executing Grid Search to RFC with Not Sexist Bigrams TFs.\n",
      "-------------------------------------------------------------------------------------------\n",
      "Reading RFC with Unigrams TFs, Likes, Dislikes, Chars and Words quantity. Model\n",
      "Executing Grid Search to RFC with Unigrams TFs, Likes, Dislikes, Chars and Words quantity.\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from classifiers.svm import SVM\n",
    "from classifiers.knn import KNN\n",
    "from classifiers.rfc import RFC\n",
    "\n",
    "svm_classifier = SVM()\n",
    "svm_params = dict(gamma=[1.0], C=[10.0])\n",
    "svm_classifier.train_models(svm_params, features)\n",
    "\n",
    "knn_classifier = KNN()\n",
    "knn_params = dict(n_neighbors=[3, 5, 11, 19],\n",
    "                  weights=['uniform', 'distance'],\n",
    "                  metric=['euclidean', 'manhattan'])\n",
    "knn_classifier.train_models(knn_params, features)\n",
    "\n",
    "rfc_classifier = RFC()\n",
    "rfc_params = { \n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['entropy']\n",
    "}\n",
    "rfc_classifier.train_models(rfc_params, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> SVM with Unigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99593 \t 0.91356\n",
      "recall\t\t 0.91390 \t 0.99589\n",
      "f1\t\t 0.95310 \t 0.95291\n",
      "\n",
      ">>>> SVM with TF to 100 sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.98464 \t 0.84894\n",
      "recall\t\t 0.83984 \t 0.98563\n",
      "f1\t\t 0.90641 \t 0.91214\n",
      "\n",
      ">>>> SVM with TF to 100 not sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97169 \t 0.82199\n",
      "recall\t\t 0.80749 \t 0.97419\n",
      "f1\t\t 0.88195 \t 0.89161\n",
      "\n",
      ">>>> SVM with Char quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.63525 \t 0.64626\n",
      "recall\t\t 0.73048 \t 0.53988\n",
      "f1\t\t 0.67950 \t 0.58821\n",
      "\n",
      ">>>> SVM with Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.56838 \t 0.55446\n",
      "recall\t\t 0.68610 \t 0.42845\n",
      "f1\t\t 0.62165 \t 0.48324\n",
      "\n",
      ">>>> SVM with Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.79441 \t 0.79767\n",
      "recall\t\t 0.82246 \t 0.76628\n",
      "f1\t\t 0.80806 \t 0.78147\n",
      "\n",
      ">>>> SVM with Likes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.58781 \t 0.55249\n",
      "recall\t\t 0.60294 \t 0.53666\n",
      "f1\t\t 0.59511 \t 0.54424\n",
      "\n",
      ">>>> SVM with Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.60595 \t 0.54012\n",
      "recall\t\t 0.49973 \t 0.64370\n",
      "f1\t\t 0.54735 \t 0.58714\n",
      "\n",
      ">>>> SVM with Likes and Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.74127 \t 0.63299\n",
      "recall\t\t 0.59064 \t 0.77390\n",
      "f1\t\t 0.65733 \t 0.69633\n",
      "\n",
      ">>>> SVM with Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97836 \t 0.97405\n",
      "recall\t\t 0.97620 \t 0.97625\n",
      "f1\t\t 0.97725 \t 0.97510\n",
      "\n",
      ">>>> SVM with Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.62580 \t 0.90248\n",
      "recall\t\t 0.96337 \t 0.36804\n",
      "f1\t\t 0.75869 \t 0.52246\n",
      "\n",
      ">>>> SVM with Seixst Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.62580 \t 0.90248\n",
      "recall\t\t 0.96337 \t 0.36804\n",
      "f1\t\t 0.75869 \t 0.52246\n",
      "\n",
      ">>>> SVM with Not Sexist Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.62580 \t 0.90248\n",
      "recall\t\t 0.96337 \t 0.36804\n",
      "f1\t\t 0.75869 \t 0.52246\n",
      "\n",
      ">>>> SVM with Ngrams and Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99392 \t 0.91685\n",
      "recall\t\t 0.91765 \t 0.99384\n",
      "f1\t\t 0.95421 \t 0.95375\n",
      "\n",
      ">>>> SVM with Unigrams TFs, Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 1.00000 \t 0.99563\n",
      "recall\t\t 0.99599 \t 1.00000\n",
      "f1\t\t 0.99799 \t 0.99781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_classifier.report_results(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> KNN with Unigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99766 \t 0.91345\n",
      "recall\t\t 0.91364 \t 0.99765\n",
      "f1\t\t 0.95375 \t 0.95366\n",
      "\n",
      ">>>> KNN with TF to 100 sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.98680 \t 0.84834\n",
      "recall\t\t 0.83877 \t 0.98768\n",
      "f1\t\t 0.90670 \t 0.91267\n",
      "\n",
      ">>>> KNN with TF to 100 not sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97010 \t 0.82135\n",
      "recall\t\t 0.80695 \t 0.97273\n",
      "f1\t\t 0.88099 \t 0.89062\n",
      "\n",
      ">>>> KNN with Char quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.61479 \t 0.60027\n",
      "recall\t\t 0.67433 \t 0.53636\n",
      "f1\t\t 0.64309 \t 0.56637\n",
      "\n",
      ">>>> KNN with Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.54601 \t 0.53698\n",
      "recall\t\t 0.75588 \t 0.31056\n",
      "f1\t\t 0.63397 \t 0.39327\n",
      "\n",
      ">>>> KNN with Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.60033 \t 0.58013\n",
      "recall\t\t 0.65615 \t 0.52082\n",
      "f1\t\t 0.62691 \t 0.54873\n",
      "\n",
      ">>>> KNN with Likes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.55377 \t 0.52182\n",
      "recall\t\t 0.63128 \t 0.44164\n",
      "f1\t\t 0.58981 \t 0.47809\n",
      "\n",
      ">>>> KNN with Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.51746 \t 0.46494\n",
      "recall\t\t 0.66738 \t 0.31730\n",
      "f1\t\t 0.58289 \t 0.37706\n",
      "\n",
      ">>>> KNN with Likes and Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.59380 \t 0.59043\n",
      "recall\t\t 0.69920 \t 0.47537\n",
      "f1\t\t 0.64214 \t 0.52656\n",
      "\n",
      ">>>> KNN with Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.77663 \t 0.76345\n",
      "recall\t\t 0.78743 \t 0.75161\n",
      "f1\t\t 0.78194 \t 0.75742\n",
      "\n",
      ">>>> KNN with Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.85369 \t 0.58427\n",
      "recall\t\t 0.39893 \t 0.92551\n",
      "f1\t\t 0.54331 \t 0.71626\n",
      "\n",
      ">>>> KNN with Seixst Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.85335 \t 0.58384\n",
      "recall\t\t 0.39786 \t 0.92551\n",
      "f1\t\t 0.54225 \t 0.71594\n",
      "\n",
      ">>>> KNN with Not Sexist Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.85335 \t 0.58384\n",
      "recall\t\t 0.39786 \t 0.92551\n",
      "f1\t\t 0.54225 \t 0.71594\n",
      "\n",
      ">>>> KNN with Ngrams and Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.99565 \t 0.91673\n",
      "recall\t\t 0.91738 \t 0.99560\n",
      "f1\t\t 0.95487 \t 0.95450\n",
      "\n",
      ">>>> KNN with Unigrams TFs, Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 1.00000 \t 0.99447\n",
      "recall\t\t 0.99492 \t 1.00000\n",
      "f1\t\t 0.99745 \t 0.99722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_classifier.report_results(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> RFC with Unigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97187 \t 0.86255\n",
      "recall\t\t 0.85829 \t 0.97273\n",
      "f1\t\t 0.91143 \t 0.91424\n",
      "\n",
      ">>>> RFC with TF to 100 sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97276 \t 0.81082\n",
      "recall\t\t 0.79198 \t 0.97566\n",
      "f1\t\t 0.87293 \t 0.88554\n",
      "\n",
      ">>>> RFC with TF to 100 not sexist unigrams results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.95241 \t 0.78477\n",
      "recall\t\t 0.76016 \t 0.95836\n",
      "f1\t\t 0.84542 \t 0.86288\n",
      "\n",
      ">>>> RFC with Char quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.54888 \t 0.56347\n",
      "recall\t\t 0.80749 \t 0.27214\n",
      "f1\t\t 0.65350 \t 0.36683\n",
      "\n",
      ">>>> RFC with Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.54366 \t 0.55220\n",
      "recall\t\t 0.81604 \t 0.24868\n",
      "f1\t\t 0.65252 \t 0.34262\n",
      "\n",
      ">>>> RFC with Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.56985 \t 0.61102\n",
      "recall\t\t 0.80722 \t 0.33167\n",
      "f1\t\t 0.66803 \t 0.42970\n",
      "\n",
      ">>>> RFC with Likes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.57065 \t 0.54218\n",
      "recall\t\t 0.62861 \t 0.48152\n",
      "f1\t\t 0.59805 \t 0.50977\n",
      "\n",
      ">>>> RFC with Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.58946 \t 0.53348\n",
      "recall\t\t 0.51631 \t 0.60587\n",
      "f1\t\t 0.55015 \t 0.56714\n",
      "\n",
      ">>>> RFC with Likes and Disikes quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.58492 \t 0.56213\n",
      "recall\t\t 0.64679 \t 0.49648\n",
      "f1\t\t 0.61401 \t 0.52681\n",
      "\n",
      ">>>> RFC with Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.60587 \t 0.57609\n",
      "recall\t\t 0.63102 \t 0.54956\n",
      "f1\t\t 0.61799 \t 0.56225\n",
      "\n",
      ">>>> RFC with Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.58356 \t 0.92357\n",
      "recall\t\t 0.98235 \t 0.23109\n",
      "f1\t\t 0.73216 \t 0.36951\n",
      "\n",
      ">>>> RFC with Seixst Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.58775 \t 0.93402\n",
      "recall\t\t 0.98422 \t 0.24282\n",
      "f1\t\t 0.73598 \t 0.38526\n",
      "\n",
      ">>>> RFC with Not Sexist Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.58812 \t 0.94091\n",
      "recall\t\t 0.98610 \t 0.24252\n",
      "f1\t\t 0.73680 \t 0.38553\n",
      "\n",
      ">>>> RFC with Ngrams and Bigrams TFs results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97197 \t 0.87319\n",
      "recall\t\t 0.87086 \t 0.97243\n",
      "f1\t\t 0.91852 \t 0.92005\n",
      "\n",
      ">>>> RFC with Unigrams TFs, Likes, Dislikes, Char and Word quantity results\n",
      "\t\t sexist \t not-sexist\n",
      "precision\t 0.97746 \t 0.86299\n",
      "recall\t\t 0.85802 \t 0.97830\n",
      "f1\t\t 0.91374 \t 0.91695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_classifier.report_results(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
